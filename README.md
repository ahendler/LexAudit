# LexAudit
[![Status](https://img.shields.io/badge/status-under%20development-blue)](https://github.com/seu-usuario/lexaudit)
[![Python Version](https://img.shields.io/badge/Python%3A%203.13-blue)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

**LexAudit** is an audit and validation system for legal citations in Brazilian documents. It verifies whether cited laws, articles, paragraphs, and ~~jurisprudence~~ are correct, up-to-date, and contextually valid, combating outdated references or hallucinations generated by LLMs.

--- 

## The Problem

Legal documents (petitions, legal opinions, public notices) depend on the accuracy of their citations (laws and jurisprudence). However, it's increasingly common to find serious problems:

* **Repealed/Outdated Laws:** The cited text no longer corresponds to the current wording of the law.
* **Incorrect References:** The article, paragraph, or item referenced is wrong ("broken pointer").
* **Non-existent Citations:** The reference simply doesn't exist, often the result of hallucinations from LLMs used in drafting.
* **Out-of-Context Usage:** The law exists, but the author's claim in the document is not supported (or is contradicted) by the legal text.

These errors compromise legal certainty, the validity of arguments, and the quality of decisions.

## LexAudit Pipeline

LexAudit processes a raw document through an automatic 4-stage validation pipeline, generating a clear and auditable audit report for each citation found.

1.  **[STAGE 1] Extraction (Linker):** The system reads the document and identifies all mentions of regulations (e.g., "Art. 5º da CF") and jurisprudence (e.g., "REsp nº 1.234.567"). This stage uses specialized NER models, replacing the old LexML Linker.
2.  **[STAGE 2] Resolution:** Each textual mention is converted into a canonical identifier (such as a `URN:LEX` for laws or a standard CNJ case number).
3.  **[STAGE 3] Retrieval:** The system queries official sources (LexML, STF, STJ APIs) to retrieve the *true* and *updated* text of the cited regulation or decision.
4.  **[STAGE 4] Validation (RAG Agent):** An AI Agent (using RAG) compares the original document text (what the author *claimed*) with the text retrieved from the official source (what the law *actually says*). The agent then classifies the citation (Correct, Outdated, Incorrect, Non-existent) and generates a justification based on evidence.

## Repository Structure (Suggestion)

```
lexaudit/
│
├── config/         # Configurations and API keys
│   └── .env.example
│
├── data/           # Validation datasets (e.g., LeNER-Br, mutation corpus)
│
├── notebooks/      # Jupyter Notebooks for exploration, prototyping and R&D
│   ├── 01_explore_data.ipynb
│   ├── 02_dev_linker.ipynb
│   └── 03_dev_rag_agent.ipynb
│
├── src/            # Main application source code
│   └── lexaudit/   # The installable Python package
│       │
│       ├── extraction/   # [STAGE 1] Citation extraction modules (Linkers)
│       ├── retrieval/    # [STAGE 3] API clients for sources (LexML, STF) - merged with resolution
│       ├── validation/   # [STAGE 4] RAG Agent validation logic
│       │
│       ├── prompts/      # Prompt templates used by RAG Agents
│       │   ├── __init__.py
│       │   ├── validation.py
│       │   └── templates.py
│       │
│       ├── core/         # Pipeline orchestration and data models (Pydantic)
│       │   ├── pipeline.py
│       │   ├── models.py
│       │   └── settings.py
│       │
│       └── main.py       # Entry point (FastAPI or CLI)
│
├── tests/          # Unit and integration tests (Pytest)
│
├── .gitignore
├── LICENSE
├── README.md
└── requirements.txt
```

## Installation

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/ahendler/lexaudit.git
    cd lexaudit
    ```

2.  **Create a virtual environment and install dependencies:**
    ```bash
    python3 -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    pip install -r requirements.txt
    ```

3.  **Install the package in development mode:**
    ```bash
    pip install -e .
    ```

4.  **Configure LLM settings:**
    * Copy the example environment file:
        ```bash
        cp config/.env.example config/.env
        ```
    * Edit `config/.env` to set your LLM provider and API key:
        ```bash
        LLM_PROVIDER=openai  # or anthropic, ollama, etc.
        LLM_MODEL=gpt-4o-mini
        OPENAI_API_KEY=your-key-here
        ```

## Running the Pipeline

After installation, you can run the pipeline in multiple ways:

**Option 1 - As a command (after installing with `pip install -e .`):**
```bash
lexaudit
```

**Option 2 - As a Python module:**
```bash
python3 -m lexaudit.main
```

The pipeline will load sample data from `data/cleaned/stj/sample_10_with_fulltext.json` and process the legal citations through the extraction, retrieval, and resolution stages.

## How to Use (Programmatic Example)

The pipeline can be invoked programmatically:

```python
from lexaudit.core.pipeline import LexAuditPipeline

# Load the pipeline (it will instantiate the Extractor, Retriever, Resolver)
auditor = LexAuditPipeline()

document_text = """
Segundo o Art. 5º, inciso XI, da Constituição Federal, "a casa é asilo 
inviolável do indivíduo".

Conforme a Lei nº 8.112 de 1990, em seu Art. 999, o servidor será 
aposentado compulsoriamente.
"""

# Execute the complete audit (currently runs extraction placeholder + retrieval + resolution)
report = auditor.run(document_text)

# Process the results
for citation in report['extracted_citations']:
    print(f"Citation: {citation.original_text}")
    print(f"Type: {citation.citation_type}")
    print(f"Normalized: {citation.normalized_reference}\n")
```

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.
