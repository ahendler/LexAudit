# LexAudit âš–ï¸
[![Status](https://img.shields.io/badge/status-under%20development-blue)](https://github.com/seu-usuario/lexaudit)
[![Python Version](https://img.shields.io/badge/Python%3A%203.13-blue)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

**LexAudit** is an audit and validation system for legal citations in Brazilian documents. It verifies whether cited laws, articles, paragraphs, and ~~jurisprudence~~ are correct, up-to-date, and contextually valid, combating outdated references or hallucinations generated by LLMs.

--- 

## The Problem

Legal documents (petitions, legal opinions, public notices) depend on the accuracy of their citations (laws and jurisprudence). However, it's increasingly common to find serious problems:

* **Repealed/Outdated Laws:** The cited text no longer corresponds to the current wording of the law.
* **Incorrect References:** The article, paragraph, or item referenced is wrong ("broken pointer").
* **Non-existent Citations:** The reference simply doesn't exist, often the result of hallucinations from LLMs used in drafting.
* **Out-of-Context Usage:** The law exists, but the author's claim in the document is not supported (or is contradicted) by the legal text.

These errors compromise legal certainty, the validity of arguments, and the quality of decisions.

## LexAudit Pipeline

LexAudit processes a raw document through an automatic 4-stage validation pipeline, generating a clear and auditable audit report for each citation found.

1.  **[STAGE 1] Extraction (Linker):** The system reads the document and identifies all mentions of regulations (e.g., "Art. 5Âº da CF") and jurisprudence (e.g., "REsp nÂº 1.234.567"). This stage uses specialized NER models, replacing the old LexML Linker.
2.  **[STAGE 2] Resolution:** Each textual mention is converted into a canonical identifier (such as a `URN:LEX` for laws or a standard CNJ case number).
3.  **[STAGE 3] Retrieval:** The system queries official sources (LexML, STF, STJ APIs) to retrieve the *true* and *updated* text of the cited regulation or decision.
4.  **[STAGE 4] Validation (RAG Agent):** An AI Agent (using RAG) compares the original document text (what the author *claimed*) with the text retrieved from the official source (what the law *actually says*). The agent then classifies the citation (Correct, Outdated, Incorrect, Non-existent) and generates a justification based on evidence.

## Repository Structure (Suggestion)

```
lexaudit/
â”‚
â”œâ”€â”€ config/         # Configurations and API keys
â”‚   â””â”€â”€ .env.example
â”‚
â”œâ”€â”€ data/           # Validation datasets (e.g., LeNER-Br, mutation corpus)
â”‚
â”œâ”€â”€ notebooks/      # Jupyter Notebooks for exploration, prototyping and R&D
â”‚   â”œâ”€â”€ 01_explore_data.ipynb
â”‚   â”œâ”€â”€ 02_dev_linker.ipynb
â”‚   â””â”€â”€ 03_dev_rag_agent.ipynb
â”‚
â”œâ”€â”€ src/            # Main application source code
â”‚   â””â”€â”€ lexaudit/   # The installable Python package
â”‚       â”‚
â”‚       â”œâ”€â”€ extraction/   # [STAGE 1] Citation extraction modules (Linkers)
â”‚       â”œâ”€â”€ retrieval/    # [STAGE 3] API clients for sources (LexML, STF) - merged with resolution
â”‚       â”œâ”€â”€ validation/   # [STAGE 4] RAG Agent validation logic
â”‚       â”‚
â”‚       â”œâ”€â”€ prompts/      # Prompt templates used by RAG Agents
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ validation.py
â”‚       â”‚   â””â”€â”€ templates.py
â”‚       â”‚
â”‚       â”œâ”€â”€ core/         # Pipeline orchestration and data models (Pydantic)
â”‚       â”‚   â”œâ”€â”€ pipeline.py
â”‚       â”‚   â”œâ”€â”€ models.py
â”‚       â”‚   â””â”€â”€ settings.py
â”‚       â”‚
â”‚       â””â”€â”€ main.py       # Entry point (FastAPI or CLI)
â”‚
â”œâ”€â”€ tests/          # Unit and integration tests (Pytest)
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## Installation

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/ahendler/lexaudit.git
    cd lexaudit
    ```

2.  **Create a virtual environment and install dependencies:**
    ```bash
    python3 -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    pip install -r requirements.txt
    ```

3.  **Install the package in development mode:**
    ```bash
    pip install -e .
    ```

4.  **Configure your API keys (when needed):**
    * Copy the example environment file:
        ```bash
        cp config/.env.example .env
        ```
    * Edit the `.env` file and add your keys (e.g., `OPENAI_API_KEY`).

## Running the Pipeline

After installation, you can run the pipeline in multiple ways:

**Option 1 - As a command (after installing with `pip install -e .`):**
```bash
lexaudit
```

**Option 2 - As a Python module:**
```bash
python3 -m lexaudit.main
```

**Option 3 - Direct execution:**
```bash
python3 src/lexaudit/main.py
```

The pipeline will load sample data from `data/cleaned/stj/sample_10_with_fulltext.json` and process the legal citations through the extraction, retrieval, and resolution stages.

## Current Implementation Status

The project is currently in active development. See [IMPLEMENTATION_STATUS.md](IMPLEMENTATION_STATUS.md) for detailed progress.

**Current Stage: Base Pipeline Setup**
- âœ… Data models defined (Citation, RetrievedDocument, ResolvedCitation)
- âœ… Placeholder extraction (forwards existing citations from JSON)
- âœ… Base retrieval module structure
- âœ… Base resolution module structure
- âœ… Pipeline orchestrator
- âœ… Main entry point to load and process sample data
- ğŸš§ Extraction logic (in progress by team member)
- ğŸ”œ Retrieval implementation (next step)
- ğŸ”œ Resolution implementation (next step)
- ğŸ”œ Validation RAG Agent

## How to Use (Programmatic Example)

The pipeline can be invoked programmatically:

```python
from lexaudit.core.pipeline import LexAuditPipeline

# Load the pipeline (it will instantiate the Extractor, Retriever, Resolver)
auditor = LexAuditPipeline()

document_text = """
Segundo o Art. 5Âº, inciso XI, da ConstituiÃ§Ã£o Federal, "a casa Ã© asilo 
inviolÃ¡vel do indivÃ­duo".

Conforme a Lei nÂº 8.112 de 1990, em seu Art. 999, o servidor serÃ¡ 
aposentado compulsoriamente.
"""

# Execute the complete audit (currently runs extraction placeholder + retrieval + resolution)
report = auditor.run(document_text)

# Process the results
for citation in report['extracted_citations']:
    print(f"Citation: {citation.original_text}")
    print(f"Type: {citation.citation_type}")
    print(f"Normalized: {citation.normalized_reference}\n")
```

### Current Output Example:

```
Processing document: acÃ³rdÃ£o 202300123456
Extracted 15 citations

=== EXTRACTION RESULTS ===
Citation 1: Lei n. 9.656/1998
  Type: legal
  Normalized: Lei 9656/1998

Citation 2: Lei n. 9.961/2000
  Type: legal
  Normalized: Lei 9961/2000
...

=== RETRIEVAL RESULTS ===
Retrieved 0 documents (placeholder - not implemented yet)

=== RESOLUTION RESULTS ===
Resolved 0 citations (placeholder - not implemented yet)
```

## ğŸ“œ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.
