# LexAudit
[![Status](https://img.shields.io/badge/status-under%20development-blue)](https://github.com/seu-usuario/lexaudit)
[![Python Version](https://img.shields.io/badge/Python%3A%203.13-blue)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

**LexAudit** is an audit and validation system for legal citations in Brazilian documents. It verifies whether cited laws, articles, paragraphs, and ~~jurisprudence~~ are correct, up-to-date, and contextually valid, combating outdated references or hallucinations generated by LLMs.

--- 

## The Problem

Legal documents (petitions, legal opinions, public notices) depend on the accuracy of their citations (laws and jurisprudence). However, it's increasingly common to find serious problems:

* **Repealed/Outdated Laws:** The cited text no longer corresponds to the current wording of the law.
* **Incorrect References:** The article, paragraph, or item referenced is wrong ("broken pointer").
* **Non-existent Citations:** The reference simply doesn't exist, often the result of hallucinations from LLMs used in drafting.
* **Out-of-Context Usage:** The law exists, but the author's claim in the document is not supported (or is contradicted) by the legal text.

These errors compromise legal certainty, the validity of arguments, and the quality of decisions.

## LexAudit Pipeline

LexAudit processes a raw document through an automatic 4-stage validation pipeline, generating a clear and auditable audit report for each citation found.

1.  **[STAGE 1] Extraction:** The system reads the document and identifies all mentions of regulations (e.g., "Art. 5º da CF") and jurisprudence (e.g., "REsp nº 1.234.567").
2.  **[STAGE 2] Resolution:** Each textual mention is converted into a canonical identifier (URN:LEX) using an LLM.
3.  **[STAGE 3] Retrieval:** The system searches Google (via SerpAPI) for official sources and fetches the full text from government websites (planalto.gov.br, normas.leg.br, etc.).
4.  **[STAGE 4] Validation (RAG Agent):** An AI Agent (using RAG) compares the document text with the retrieved official text, classifying the citation and generating justification.

## Repository Structure (Suggestion)

```
lexaudit/
│
├── config/         # Configurations and API keys
│   └── .env.example
│
├── data/           # Validation datasets (e.g., LeNER-Br, mutation corpus)
│
├── notebooks/      # Jupyter Notebooks for exploration, prototyping and R&D
│   ├── 01_explore_data.ipynb
│   ├── 02_dev_linker.ipynb
│   └── 03_dev_rag_agent.ipynb
│
├── src/            # Main application source code
│   └── lexaudit/   # The installable Python package
│       │
│       ├── extraction/   # [STAGE 1] Citation extraction modules
│       ├── retrieval/    # [STAGE 2 & 3] Resolution (LLM) + Retrieval (SerpAPI)
│       ├── validation/   # [STAGE 4] RAG Agent validation logic
│       │
│       ├── prompts/      # Prompt templates used by RAG Agents
│       │   ├── __init__.py
│       │   ├── validation.py
│       │   └── templates.py
│       │
│       ├── core/         # Pipeline orchestration and data models (Pydantic)
│       │   ├── pipeline.py
│       │   ├── models.py
│       │   └── settings.py
│       │
│       └── main.py       # Entry point (FastAPI or CLI)
│
├── tests/          # Unit and integration tests (Pytest)
│
├── .gitignore
├── LICENSE
├── README.md
└── requirements.txt
```

## Installation

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/ahendler/lexaudit.git
    cd lexaudit
    ```

2.  **Create a virtual environment and install dependencies:**
    ```bash
    python3 -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    pip install -r requirements.txt
    ```

3.  **Install the package in development mode:**
    ```bash
    pip install -e .
    ```

4.  **Configure API keys:**
    * Copy the example environment file:
        ```bash
        cp config/.env.example config/.env
        ```
    * Edit `config/.env` to set your API keys:
        ```bash
        LLM_PROVIDER=gemini  # or anthropic, ollama, etc.
        LLM_MODEL=gemini-2.5-flash
        GOOGLE_API_KEY=your-gemini-key-here
        SERPAPI_API_KEY=your-serpapi-key-here  # Get free key at serpapi.com
        ```

## Running the Pipeline

After installation, you can run the pipeline in multiple ways:

**Option 1 - As a command (after installing with `pip install -e .`):**
```bash
lexaudit
```

**Option 2 - As a Python module:**
```bash
python3 -m lexaudit.main
```

The pipeline will load sample data from `data/cleaned/stj/sample_10_with_fulltext.json` and process citations through extraction, resolution, and retrieval stages.

## How to Use (Programmatic Example)

The pipeline can be invoked programmatically:

```python
from lexaudit.core.pipeline import LexAuditPipeline

# Load the pipeline (it will instantiate the Extractor, Retriever, Resolver)
auditor = LexAuditPipeline()

document_text = """
Segundo o Art. 5º, inciso XI, da Constituição Federal, "a casa é asilo 
inviolável do indivíduo".

Conforme a Lei nº 8.112 de 1990, em seu Art. 999, o servidor será 
aposentado compulsoriamente.
"""

# Execute the complete audit (extraction → resolution → retrieval)
report = auditor.run(document_text)

# Process the results
for citation in report['extracted_citations']:
    print(f"Citation: {citation.original_text}")
    print(f"Type: {citation.citation_type}")
    print(f"Normalized: {citation.normalized_reference}\n")
```

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.
